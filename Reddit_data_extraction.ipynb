{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPhi5jRWe/Vkh1/6xlJXOPg",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/decisionenabler-sk/reddit_data_project/blob/main/Reddit_data_extraction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Install library to scrape Reddit data"
      ],
      "metadata": {
        "id": "mOc6LSTQ_v9Q"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZxdGYw7d6uIL"
      },
      "outputs": [],
      "source": [
        "!pip install praw\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import the library and attempt to autheticate user creds"
      ],
      "metadata": {
        "id": "QyFc6keC_-kV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import praw\n",
        "import datetime\n",
        "import pytz\n",
        "# Authenticate your script using your Reddit app credentials\n",
        "\n",
        "reddit = praw.Reddit(\n",
        "    client_id=CLIENT_ID,\n",
        "    client_secret=CLIENT_SECRET,\n",
        "    redirect_uri=REDIRECT_URI,\n",
        "    user_agent=USER_AGENT\n",
        ")\n",
        "\n",
        "# You can use the authenticated `reddit` object to interact with Reddit API\n"
      ],
      "metadata": {
        "id": "Wpcjz7D9_sZX"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install google-cloud-bigquery\n",
        "!pip install pandas"
      ],
      "metadata": {
        "id": "EMFedGvdzhrR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "uHnVsQt6Je37"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Setup the dataset and table in bigquery. Define the schema for our table"
      ],
      "metadata": {
        "id": "YA2HfVcmFZy5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.cloud import bigquery\n",
        "from google.cloud.exceptions import NotFound\n",
        "from google.colab import auth\n",
        "\n",
        "\n",
        "# Set up BigQuery client\n",
        "\n",
        "auth.authenticate_user()\n",
        "!gcloud config set project {PROJECT_ID}\n",
        "client = bigquery.Client(project=PROJECT_ID)\n",
        "# Set up dataset and table info\n",
        "dataset_id = 'reddit_otf_data'\n",
        "table_id = 'intelposts'\n",
        "\n",
        "# Create dataset (if it doesn't exist)\n",
        "dataset_ref = client.dataset(dataset_id)\n",
        "try:\n",
        "    client.get_dataset(dataset_ref)\n",
        "except NotFound:\n",
        "    dataset = bigquery.Dataset(dataset_ref)\n",
        "    client.create_dataset(dataset)\n",
        "\n",
        "# Create table (if it doesn't exist)\n",
        "schema = [\n",
        "    bigquery.SchemaField('title', 'STRING'),\n",
        "    bigquery.SchemaField('score', 'INTEGER'),\n",
        "    bigquery.SchemaField('tag', 'STRING'),\n",
        "    bigquery.SchemaField('url', 'STRING'),\n",
        "    bigquery.SchemaField('body', 'STRING'),\n",
        "    bigquery.SchemaField('createdDate', 'TIMESTAMP'),\n",
        "    bigquery.SchemaField('upvoteRatio', 'FLOAT'),\n",
        "    bigquery.SchemaField('numComments', 'INTEGER'),\n",
        "    bigquery.SchemaField('topComment', 'STRING')\n",
        "]\n",
        "table_ref = dataset_ref.table(table_id)\n",
        "try:\n",
        "    client.get_table(table_ref)\n",
        "except NotFound:\n",
        "    table = bigquery.Table(table_ref, schema=schema)\n",
        "    client.create_table(table)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LszJ_KoQzrh1",
        "outputId": "b7a3bf6f-f3db-4117-c681-89e6e52a4a22"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Updated property [core/project].\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Let's look at the subreddit for Orange Theory Workout to get posts related to the community\n",
        "2. Then we'll store the data to a dataframe, transform the data types of the columns"
      ],
      "metadata": {
        "id": "6H0srkWGAIVJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we will store this in a bigquery table"
      ],
      "metadata": {
        "id": "gZgETgE6zd0O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import datetime\n",
        "# Specify the subreddit you want to extract data from\n",
        "subreddit_name = 'orangetheory'\n",
        "\n",
        "# Get the subreddit object\n",
        "subreddit = reddit.subreddit(subreddit_name)\n",
        "# Prepare the DataFrame with the data to be inserted\n",
        "data = []\n",
        "# Specify the subreddit tag you want to search\n",
        "tags = ['Early Intel', 'Daily Workout', 'Lift 45 and Tornado Templates']\n",
        "\n",
        "# Iterate over the posts and insert data into the BigQuery table\n",
        "for tag in tags:\n",
        "    intel_posts = subreddit.search(f'flair:\"{tag}\"', sort='new', limit=10)\n",
        "\n",
        "    # Iterate over the posts\n",
        "    for post in intel_posts:\n",
        "        # Convert the UTC timestamp to PST\n",
        "        pst_tz = pytz.timezone('US/Pacific')\n",
        "        utc_dt = datetime.datetime.utcfromtimestamp(post.created_utc)\n",
        "        pst_dt = utc_dt.replace(tzinfo=pytz.utc).astimezone(pst_tz)\n",
        "\n",
        "        data.append({\n",
        "            'title': str(post.title),\n",
        "            'score': int(post.score),\n",
        "            'tag': str(post.link_flair_text),\n",
        "            'url': str(post.url),\n",
        "            'body': str(post.selftext),\n",
        "            'createdDate': datetime.datetime.strptime(pst_dt.strftime(\"%Y-%m-%d %H:%M:%S\"), \"%Y-%m-%d %H:%M:%S\"),\n",
        "            'upvoteRatio': float(post.upvote_ratio),\n",
        "            'numComments': int(post.num_comments),\n",
        "            'topComment': str(post.comments[0].body if len(post.comments) > 0 else \"No comments found.\")\n",
        "        })\n",
        "\n",
        "# Create a DataFrame from the collected data\n",
        "df = pd.DataFrame(data)\n",
        "\n"
      ],
      "metadata": {
        "id": "iV1C8KXj6qws"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the data types of the DataFrame columns\n",
        "df.head()\n",
        "print(df.dtypes)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IWJSRrjSJGu6",
        "outputId": "af458365-b916-4d81-efcb-67b4bf584d1b"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "title                  object\n",
            "score                   int64\n",
            "tag                    object\n",
            "url                    object\n",
            "body                   object\n",
            "createdDate    datetime64[ns]\n",
            "upvoteRatio           float64\n",
            "numComments             int64\n",
            "topComment             object\n",
            "dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Once the dataframe is ready we'll perform the insert operation in to the big query table"
      ],
      "metadata": {
        "id": "rLjv45d3Mswv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the DataFrame into BigQuery table\n",
        "job_config = bigquery.LoadJobConfig()\n",
        "job_config.write_disposition = bigquery.WriteDisposition.WRITE_APPEND\n",
        "job = client.load_table_from_dataframe(df, table_ref, job_config=job_config)\n",
        "job.result()  # Wait for the job to complete\n",
        "\n",
        "print(f\"Data loaded successfully into BigQuery table: {table_id}\")\n",
        "\n",
        "# Clear the DataFrame\n",
        "df.drop(df.index, inplace=True)\n",
        "\n",
        "print(\"DataFrame cleared.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eh5P5K4OJBgj",
        "outputId": "dca233c6-7f40-4748-ba06-ccbda55d5f57"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data loaded successfully into BigQuery table: intelposts\n",
            "DataFrame cleared.\n"
          ]
        }
      ]
    }
  ]
}