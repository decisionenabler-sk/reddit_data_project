{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO4d6+8y5Ex6oVF4Oo16OIw",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/decisionenabler-sk/reddit_data_project/blob/main/Reddit_data_extraction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Install library to scrape Reddit data"
      ],
      "metadata": {
        "id": "mOc6LSTQ_v9Q"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZxdGYw7d6uIL",
        "outputId": "958ef0a3-c814-4d57-99a7-43db7dca47ff"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting praw\n",
            "  Downloading praw-7.7.0-py3-none-any.whl (189 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m189.4/189.4 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting prawcore<3,>=2.1 (from praw)\n",
            "  Downloading prawcore-2.3.0-py3-none-any.whl (16 kB)\n",
            "Collecting update-checker>=0.18 (from praw)\n",
            "  Downloading update_checker-0.18.0-py3-none-any.whl (7.0 kB)\n",
            "Requirement already satisfied: websocket-client>=0.54.0 in /usr/local/lib/python3.10/dist-packages (from praw) (1.5.1)\n",
            "Requirement already satisfied: requests<3.0,>=2.6.0 in /usr/local/lib/python3.10/dist-packages (from prawcore<3,>=2.1->praw) (2.27.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0,>=2.6.0->prawcore<3,>=2.1->praw) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0,>=2.6.0->prawcore<3,>=2.1->praw) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests<3.0,>=2.6.0->prawcore<3,>=2.1->praw) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0,>=2.6.0->prawcore<3,>=2.1->praw) (3.4)\n",
            "Installing collected packages: update-checker, prawcore, praw\n",
            "Successfully installed praw-7.7.0 prawcore-2.3.0 update-checker-0.18.0\n"
          ]
        }
      ],
      "source": [
        "!pip install praw\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import the library and attempt to autheticate user creds"
      ],
      "metadata": {
        "id": "QyFc6keC_-kV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import praw\n",
        "import datetime\n",
        "import pytz\n",
        "# Authenticate your script using your Reddit app credentials\n",
        "\n",
        "reddit = praw.Reddit(\n",
        "    client_id=CLIENT_ID,\n",
        "    client_secret=CLIENT_SECRET,\n",
        "    redirect_uri=REDIRECT_URI,\n",
        "    user_agent=USER_AGENT\n",
        ")\n",
        "\n",
        "# You can use the authenticated `reddit` object to interact with Reddit API\n"
      ],
      "metadata": {
        "id": "Wpcjz7D9_sZX"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install google-cloud-bigquery"
      ],
      "metadata": {
        "id": "EMFedGvdzhrR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "uHnVsQt6Je37"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.cloud import bigquery\n",
        "from google.cloud.exceptions import NotFound\n",
        "from google.colab import auth\n",
        "\n",
        "# Set up BigQuery client\n",
        "\n",
        "auth.authenticate_user()\n",
        "!gcloud config set project {PROJECT_ID}\n",
        "client = bigquery.Client(project=PROJECT_ID)\n",
        "# Set up dataset and table info\n",
        "dataset_id = 'reddit_otf_data'\n",
        "table_id = 'intelposts'\n",
        "\n",
        "# Create dataset (if it doesn't exist)\n",
        "dataset_ref = client.dataset(dataset_id)\n",
        "try:\n",
        "    client.get_dataset(dataset_ref)\n",
        "except NotFound:\n",
        "    dataset = bigquery.Dataset(dataset_ref)\n",
        "    client.create_dataset(dataset)\n",
        "\n",
        "# Create table (if it doesn't exist)\n",
        "schema = [\n",
        "    bigquery.SchemaField('title', 'STRING', mode='REQUIRED'),\n",
        "    bigquery.SchemaField('score', 'INTEGER', mode='REQUIRED'),\n",
        "    bigquery.SchemaField('tag', 'STRING', mode='REQUIRED'),\n",
        "    bigquery.SchemaField('url', 'STRING', mode='REQUIRED'),\n",
        "    bigquery.SchemaField('createdDate' , 'STRING', mode='REQUIRED'),\n",
        "    bigquery.SchemaField('body', 'STRING', mode='REQUIRED'),\n",
        "    bigquery.SchemaField('numComments', 'INTEGER', mode='REQUIRED'),\n",
        "    bigquery.SchemaField('topComment', 'STRING', mode='REQUIRED'),\n",
        "    bigquery.SchemaField('upvoteRatio', 'DECIMAL', mode='REQUIRED'),\n",
        "]\n",
        "table_ref = dataset_ref.table(table_id)\n",
        "try:\n",
        "    client.get_table(table_ref)\n",
        "except NotFound:\n",
        "    table = bigquery.Table(table_ref, schema=schema)\n",
        "    client.create_table(table)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LszJ_KoQzrh1",
        "outputId": "5b8ad874-21f5-4716-e861-d14db5a9626b"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Updated property [core/project].\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's look at the subreddit for Orange Theory Workout to get posts related to the community"
      ],
      "metadata": {
        "id": "6H0srkWGAIVJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we will store this in a bigquery table"
      ],
      "metadata": {
        "id": "gZgETgE6zd0O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Specify the subreddit you want to extract data from\n",
        "subreddit_name = 'orangetheory'\n",
        "\n",
        "# Get the subreddit object\n",
        "subreddit = reddit.subreddit(subreddit_name)\n",
        "\n",
        "# Specify the subreddit tag you want to search\n",
        "tags = ['Early Intel' , 'Daily Workout', 'Lift 45 and Tornado Templates']\n",
        "\n",
        "# Get the posts with the specified tag from the subreddit, here we want to sort new posts because we want to find latest workouts\n",
        "for tag in tags:\n",
        "    intel_posts = subreddit.search(f'flair:\"{tag}\"', sort='new', limit=10)\n",
        "\n",
        "# Print the titles, URLs, bodies etc of the posts to check the results\n",
        "# for post in intel_posts:\n",
        "#     print(f'Flair: {post.link_flair_text}')\n",
        "#     print(f'Title: {post.title}')\n",
        "#     print(f'URL: {post.url}')\n",
        "#     # Convert the UTC timestamp to PST\n",
        "#     pst_tz = pytz.timezone('US/Pacific')\n",
        "#     utc_dt = datetime.datetime.utcfromtimestamp(post.created_utc)\n",
        "#     pst_dt = utc_dt.replace(tzinfo=pytz.utc).astimezone(pst_tz)\n",
        "#     print(f'CreatedDate: {pst_dt.strftime(\"%Y-%m-%d %H:%M:%S %Z%z\")}')\n",
        "#     print(f'Score {post.score}')\n",
        "#     print(f'Upvote Ratio: {post.upvote_ratio}')\n",
        "#     print(f'NumComments: {post.num_comments}')\n",
        "#     print(f'Top Comment: {post.comments[0].body if len(post.comments) > 0 else \"No comments found.\"}')\n",
        "#     print(f'Body: {post.selftext}')\n",
        "    \n",
        "    \n"
      ],
      "metadata": {
        "id": "ycRxUoJqDMKr"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Once the table is created, we will insert the data"
      ],
      "metadata": {
        "id": "CAiiFnE88Gjw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Iterate over the posts and insert data into the BigQuery table\n",
        "for post in intel_posts:\n",
        "    tag=post.link_flair_text\n",
        "    title=post.title\n",
        "    score=post.score\n",
        "    url=post.url\n",
        "    # Convert the UTC timestamp to PST\n",
        "    pst_tz = pytz.timezone('US/Pacific')\n",
        "    utc_dt = datetime.datetime.utcfromtimestamp(post.created_utc)\n",
        "    pst_dt = utc_dt.replace(tzinfo=pytz.utc).astimezone(pst_tz)\n",
        "    createdDate=pst_dt.strftime(\"%Y-%m-%d %H:%M:%S %Z%z\")\n",
        "    upvoteRatio=post.upvote_ratio\n",
        "    numComments=post.num_comments\n",
        "    topComment=post.comments[0].body if len(post.comments) > 0 else \"No comments found.\"\n",
        "    body=post.selftext"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OfvRnzVY8RKK",
        "outputId": "02cc4774-ce51-43a0-ca98-c8044e53e4b0"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:praw:It appears that you are using PRAW in an asynchronous environment.\n",
            "It is strongly recommended to use Async PRAW: https://asyncpraw.readthedocs.io.\n",
            "See https://praw.readthedocs.io/en/latest/getting_started/multiple_instances.html#discord-bots-and-asynchronous-environments for more info.\n",
            "\n",
            "WARNING:praw:It appears that you are using PRAW in an asynchronous environment.\n",
            "It is strongly recommended to use Async PRAW: https://asyncpraw.readthedocs.io.\n",
            "See https://praw.readthedocs.io/en/latest/getting_started/multiple_instances.html#discord-bots-and-asynchronous-environments for more info.\n",
            "\n",
            "WARNING:praw:It appears that you are using PRAW in an asynchronous environment.\n",
            "It is strongly recommended to use Async PRAW: https://asyncpraw.readthedocs.io.\n",
            "See https://praw.readthedocs.io/en/latest/getting_started/multiple_instances.html#discord-bots-and-asynchronous-environments for more info.\n",
            "\n",
            "WARNING:praw:It appears that you are using PRAW in an asynchronous environment.\n",
            "It is strongly recommended to use Async PRAW: https://asyncpraw.readthedocs.io.\n",
            "See https://praw.readthedocs.io/en/latest/getting_started/multiple_instances.html#discord-bots-and-asynchronous-environments for more info.\n",
            "\n",
            "WARNING:praw:It appears that you are using PRAW in an asynchronous environment.\n",
            "It is strongly recommended to use Async PRAW: https://asyncpraw.readthedocs.io.\n",
            "See https://praw.readthedocs.io/en/latest/getting_started/multiple_instances.html#discord-bots-and-asynchronous-environments for more info.\n",
            "\n",
            "WARNING:praw:It appears that you are using PRAW in an asynchronous environment.\n",
            "It is strongly recommended to use Async PRAW: https://asyncpraw.readthedocs.io.\n",
            "See https://praw.readthedocs.io/en/latest/getting_started/multiple_instances.html#discord-bots-and-asynchronous-environments for more info.\n",
            "\n",
            "WARNING:praw:It appears that you are using PRAW in an asynchronous environment.\n",
            "It is strongly recommended to use Async PRAW: https://asyncpraw.readthedocs.io.\n",
            "See https://praw.readthedocs.io/en/latest/getting_started/multiple_instances.html#discord-bots-and-asynchronous-environments for more info.\n",
            "\n",
            "WARNING:praw:It appears that you are using PRAW in an asynchronous environment.\n",
            "It is strongly recommended to use Async PRAW: https://asyncpraw.readthedocs.io.\n",
            "See https://praw.readthedocs.io/en/latest/getting_started/multiple_instances.html#discord-bots-and-asynchronous-environments for more info.\n",
            "\n",
            "WARNING:praw:It appears that you are using PRAW in an asynchronous environment.\n",
            "It is strongly recommended to use Async PRAW: https://asyncpraw.readthedocs.io.\n",
            "See https://praw.readthedocs.io/en/latest/getting_started/multiple_instances.html#discord-bots-and-asynchronous-environments for more info.\n",
            "\n",
            "WARNING:praw:It appears that you are using PRAW in an asynchronous environment.\n",
            "It is strongly recommended to use Async PRAW: https://asyncpraw.readthedocs.io.\n",
            "See https://praw.readthedocs.io/en/latest/getting_started/multiple_instances.html#discord-bots-and-asynchronous-environments for more info.\n",
            "\n",
            "WARNING:praw:It appears that you are using PRAW in an asynchronous environment.\n",
            "It is strongly recommended to use Async PRAW: https://asyncpraw.readthedocs.io.\n",
            "See https://praw.readthedocs.io/en/latest/getting_started/multiple_instances.html#discord-bots-and-asynchronous-environments for more info.\n",
            "\n"
          ]
        }
      ]
    }
  ]
}