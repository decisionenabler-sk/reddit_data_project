{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPYZRdm0f4urMbBv9EF8SA8"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Install library to scrape Reddit data"
      ],
      "metadata": {
        "id": "mOc6LSTQ_v9Q"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZxdGYw7d6uIL",
        "outputId": "a453b965-b93e-434c-a7b9-02b7880b057d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting asyncpraw\n",
            "  Downloading asyncpraw-7.7.0-py3-none-any.whl (196 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.5/196.5 kB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting aiofiles<1 (from asyncpraw)\n",
            "  Downloading aiofiles-0.8.0-py3-none-any.whl (13 kB)\n",
            "Collecting aiohttp<4 (from asyncpraw)\n",
            "  Downloading aiohttp-3.8.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m45.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting aiosqlite<=0.17.0 (from asyncpraw)\n",
            "  Downloading aiosqlite-0.17.0-py3-none-any.whl (15 kB)\n",
            "Collecting asyncio-extras<=1.3.2 (from asyncpraw)\n",
            "  Downloading asyncio_extras-1.3.2-py3-none-any.whl (8.4 kB)\n",
            "Collecting asyncprawcore<3,>=2.1 (from asyncpraw)\n",
            "  Downloading asyncprawcore-2.3.0-py3-none-any.whl (18 kB)\n",
            "Requirement already satisfied: update-checker>=0.18 in /usr/local/lib/python3.10/dist-packages (from asyncpraw) (0.18.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4->asyncpraw) (23.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4->asyncpraw) (2.0.12)\n",
            "Collecting multidict<7.0,>=4.5 (from aiohttp<4->asyncpraw)\n",
            "  Downloading multidict-6.0.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (114 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.5/114.5 kB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting async-timeout<5.0,>=4.0.0a3 (from aiohttp<4->asyncpraw)\n",
            "  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
            "Collecting yarl<2.0,>=1.0 (from aiohttp<4->asyncpraw)\n",
            "  Downloading yarl-1.9.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (268 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m20.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting frozenlist>=1.1.1 (from aiohttp<4->asyncpraw)\n",
            "  Downloading frozenlist-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (149 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m149.6/149.6 kB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting aiosignal>=1.1.2 (from aiohttp<4->asyncpraw)\n",
            "  Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
            "Requirement already satisfied: typing_extensions>=3.7.2 in /usr/local/lib/python3.10/dist-packages (from aiosqlite<=0.17.0->asyncpraw) (4.5.0)\n",
            "Collecting async-generator>=1.3 (from asyncio-extras<=1.3.2->asyncpraw)\n",
            "  Downloading async_generator-1.10-py3-none-any.whl (18 kB)\n",
            "Requirement already satisfied: requests>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from update-checker>=0.18->asyncpraw) (2.27.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.3.0->update-checker>=0.18->asyncpraw) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.3.0->update-checker>=0.18->asyncpraw) (2022.12.7)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.3.0->update-checker>=0.18->asyncpraw) (3.4)\n",
            "Installing collected packages: multidict, frozenlist, async-timeout, async-generator, aiosqlite, aiofiles, yarl, asyncio-extras, aiosignal, aiohttp, asyncprawcore, asyncpraw\n",
            "Successfully installed aiofiles-0.8.0 aiohttp-3.8.4 aiosignal-1.3.1 aiosqlite-0.17.0 async-generator-1.10 async-timeout-4.0.2 asyncio-extras-1.3.2 asyncpraw-7.7.0 asyncprawcore-2.3.0 frozenlist-1.3.3 multidict-6.0.4 yarl-1.9.2\n"
          ]
        }
      ],
      "source": [
        "!pip install asyncpraw\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import the library and attempt to autheticate user creds"
      ],
      "metadata": {
        "id": "QyFc6keC_-kV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import asyncpraw\n",
        "# Authenticate your script using your Reddit app credentials\n",
        "reddit = asyncpraw.Reddit(\n",
        "    client_id=\"CLIENT_ID\",\n",
        "    client_secret=\"CLIENT_SECRET\",\n",
        "    password=\"PASSWORD\",\n",
        "    user_agent=\"Comment Extraction (by u/USERNAME)\",\n",
        "    username=\"USERNAME\",\n",
        ")"
      ],
      "metadata": {
        "id": "Wpcjz7D9_sZX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's look at the subreddit for Orange Theory Workout to get posts related to the community"
      ],
      "metadata": {
        "id": "6H0srkWGAIVJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Specify the subreddit you want to extract data from\n",
        "subreddit_name = 'orangetheory'\n",
        "\n",
        "# Get the subreddit object\n",
        "subreddit = reddit.subreddit(subreddit_name)\n",
        "\n",
        "# Extract data from the subreddit\n",
        "hot_posts = subreddit.hot(limit=10)  # Extract top 10 posts\n",
        "daily_posts = subreddit.new(limit=10)\n",
        "\n",
        "# Iterate over the posts and print their titles and scores\n",
        "for post in hot_posts:\n",
        "    print('Title:', post.title)\n",
        "    print('Score:', post.score)\n",
        "# Specify the subreddit tag you want to search\n",
        "tag = 'Early Intel'\n",
        "\n",
        "# Get the top posts with the specified tag from the subreddit\n",
        "intel_posts = subreddit.search(f'flair:\"{tag}\"', sort='top', limit=10)\n",
        "\n",
        "# Print the titles, URLs, and bodies of the top posts\n",
        "for post in intel_posts:\n",
        "    print(f'Title: {post.title}')\n",
        "    print(f'URL: {post.url}')\n",
        "    print(f'Body: {post.selftext}')\n",
        "\n",
        "# Store the extracted data in a CSV file or database as per your project requirements\n",
        "# You can use Python's CSV module or a database library to accomplish this.\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ycRxUoJqDMKr",
        "outputId": "b1963b4c-b8cd-4e02-bac0-e62367a22a19"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:praw:It appears that you are using PRAW in an asynchronous environment.\n",
            "It is strongly recommended to use Async PRAW: https://asyncpraw.readthedocs.io.\n",
            "See https://praw.readthedocs.io/en/latest/getting_started/multiple_instances.html#discord-bots-and-asynchronous-environments for more info.\n",
            "\n",
            "WARNING:praw:It appears that you are using PRAW in an asynchronous environment.\n",
            "It is strongly recommended to use Async PRAW: https://asyncpraw.readthedocs.io.\n",
            "See https://praw.readthedocs.io/en/latest/getting_started/multiple_instances.html#discord-bots-and-asynchronous-environments for more info.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Title: ** May 2023 Monthly Highlights **\n",
            "Score: 151\n",
            "Title: Daily Workout and General Chat for Thursday, 5/11/23\n",
            "Score: 71\n",
            "Title: Friday 12 May 2023 - 2G 60 minutes\n",
            "Score: 98\n",
            "Title: Fav motivational coach quotes\n",
            "Score: 33\n",
            "Title: Forgot my Heart Rate Monitor\n",
            "Score: 31\n",
            "Title: Any advantage to signing up for Mayhem other than a $15 t-shirt?\n",
            "Score: 9\n",
            "Title: Music Suggestions\n",
            "Score: 4\n",
            "Title: I Wish They Offered Cardio Classes\n",
            "Score: 15\n",
            "Title: Top notch customer service\n",
            "Score: 45\n",
            "Title: Running on OTF treadmills\n",
            "Score: 1\n",
            "Title: Friday 12 May 2023 - 2G 60 minutes\n",
            "URL: https://www.reddit.com/r/orangetheory/comments/13eyzfd/friday_12_may_2023_2g_60_minutes/\n",
            "Body: Switch template with low benches on the floor.\n",
            "\n",
            "**Tread Block 1**\n",
            "* 1 min base\n",
            "* 1 min push\n",
            "* 1 min AO\n",
            "* 1 min WR\n",
            "* 1 min push\n",
            "* 1 min AO\n",
            "* 1 min WR\n",
            "* 30 sec AO\n",
            "* Transition to floor\n",
            "\n",
            "**Floor Block 1 - 7.5 minutes**\n",
            "* Back to back superset:\n",
            "    * 6 x reverse lunge (L)\n",
            "    * 6 x step down reverse lunge (L)\n",
            "    * 6 x reverse lunge (R)\n",
            "    * 6 x step down reverse lunge (R), rest\n",
            "* 12 x low bench bridge\n",
            "* Transition to treadmill\n",
            "\n",
            "**Tread Block 2**\n",
            "* 45 sec base\n",
            "* 45 sec push\n",
            "* 45 sec AO\n",
            "* 45 sec WR\n",
            "* 45 sec push\n",
            "* 45 sec AO\n",
            "* 45 sec WR\n",
            "* 45 sec AO\n",
            "* 45 sec WR\n",
            "* 30 sec AO\n",
            "* Transition to rower\n",
            "\n",
            "**Row Block**\n",
            "* 45 sec base row\n",
            "* 45 sec push row\n",
            "* 45 sec AO row\n",
            "* 45 sec recovery row\n",
            "* 45 sec push row\n",
            "* 45 sec AO row\n",
            "* 45 sec recovery row\n",
            "* 45 sec AO row\n",
            "* 45 sec recovery row\n",
            "* 30 sec AO row\n",
            "* Transition to treadmill\n",
            "\n",
            "**Tread Block 3**\n",
            "* 30 sec base\n",
            "* 30 sec push\n",
            "* 30 sec AO\n",
            "* 30 sec WR\n",
            "* 30 sec push\n",
            "* 30 sec AO\n",
            "* 30 sec WR\n",
            "* 30 sec AO\n",
            "* 30 sec WR\n",
            "* 30 sec AO\n",
            "* 30 sec WR\n",
            "* 30 sec AO\n",
            "* Transition to floor\n",
            "\n",
            "**Floor Block 2 - 6 minutes**\n",
            "* Back to back superset:\n",
            "    * 6 x chest press (on floor)\n",
            "    * 6 x low bench chest press, rest\n",
            "* 6 each x high plank abduction\n",
            "* Repeat until **finisher**: 30 sec high plank alt knee drive (using low bench for feet)\n",
            "\n",
            "DC commentary:\n",
            ">! Switch template today. For me this means low splats as you spend a bit of time getting to each station, wiping down etc. Having said that it was a reasonably good calorie burn and the middle switch block between treads and rower kept the heart rate high. \\\n",
            "\\\n",
            "On the treadmill the focus is on power. Each block the efforts get a bit shorter including recoveries. We were coached to keep upping our paces each round so that the heart rate doesn’t drop too much. You do have one minute all outs in the first round but only two as the last all out is just 30 seconds. The next couple of blocks aren’t too bad but again the recoveries are getting quite a bit shorter each round. Reasonable distance for the tread blocks of 5.04km (3.132 miles) given all the switching. \\\n",
            "\\\n",
            "Two floor blocks and a lone row block. The focus on the floor is all the supersets. The idea is that you lift heavy in the first round and then move to the low bench to make it that little bit harder. The row block is all cardio so it is the same as the treads with a real power focus. We were asked to watch our wattage and to increase that with each all out. \\\n",
            "\\\n",
            "Decent enough template today. I didn’t think it was too bad with probably the most difficult section being the transition from treadmills to rower and then back up to the treadmills. I give today a 3 (🪶 🪶 🪶) out of 5 for gentleness. !<\n"
          ]
        }
      ]
    }
  ]
}